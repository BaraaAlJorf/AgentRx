/scratch/baj321/conda-envs/llama3_env/lib/python3.10/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0
Loading Dataset to RAM:   0%|          | 0/616 [00:00<?, ?it/s]Loading Dataset to RAM:   2%|â–         | 13/616 [00:00<00:04, 128.90it/s]Loading Dataset to RAM:   8%|â–Š         | 50/616 [00:00<00:02, 269.70it/s]Loading Dataset to RAM:  15%|â–ˆâ–        | 91/616 [00:00<00:01, 330.08it/s]Loading Dataset to RAM:  21%|â–ˆâ–ˆ        | 129/616 [00:00<00:01, 347.34it/s]Loading Dataset to RAM:  27%|â–ˆâ–ˆâ–‹       | 167/616 [00:00<00:01, 357.70it/s]Loading Dataset to RAM:  34%|â–ˆâ–ˆâ–ˆâ–      | 208/616 [00:00<00:01, 362.75it/s]Loading Dataset to RAM:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 252/616 [00:00<00:00, 375.89it/s]Loading Dataset to RAM:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 291/616 [00:00<00:00, 371.04it/s]Loading Dataset to RAM:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 335/616 [00:00<00:00, 385.40it/s]Loading Dataset to RAM:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 376/616 [00:01<00:00, 392.60it/s]Loading Dataset to RAM:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 416/616 [00:01<00:00, 385.12it/s]Loading Dataset to RAM:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 455/616 [00:01<00:00, 371.91it/s]Loading Dataset to RAM:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 496/616 [00:01<00:00, 379.53it/s]Loading Dataset to RAM:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 537/616 [00:01<00:00, 383.65it/s]Loading Dataset to RAM:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 577/616 [00:01<00:00, 382.58it/s]Loading Dataset to RAM: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 616/616 [00:01<00:00, 382.73it/s]Loading Dataset to RAM: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 616/616 [00:01<00:00, 358.87it/s]
Running Simulation for 'SelfRefine':   0%|          | 0/616 [00:00<?, ?it/s]Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.

Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s][A
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:03<00:14,  3.72s/it][A
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:04<00:06,  2.16s/it][A
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:05<00:03,  1.65s/it][A
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:06<00:01,  1.42s/it][A
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:07<00:00,  1.01s/it][ALoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:07<00:00,  1.43s/it]
slurmstepd: error: *** JOB 13570910 ON cn265 CANCELLED AT 2025-12-17T16:37:04 ***
